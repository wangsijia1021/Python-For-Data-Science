{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3 Understanding your data II - Data Manipulations and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1 Create and Load data\n",
    "2 Data manipulations: slicing, reshaping and aggregations\n",
    "3 Feature engineering: Tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create numpy array\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "x1 = np.random.randint(10, size=6) # One-dimensional array\n",
    "x2 = np.random.randint(10, size=(3, 4)) # Two-dimensional array\n",
    "x3 = np.random.randint(10, size=(3, 4, 5)) # Three-dimensional array\n",
    "x4 = np.arange(10)\n",
    "#Create pd Series - x.values is a np array\n",
    "x = pd.Series([1,2,3],index=['a','b','c'])\n",
    "x1 = pd.Series({'a':1,'b':2,'c':3})\n",
    "#Create pandas data frames\n",
    "y = pd.DataFrame({'x':x,'x1':x1})\n",
    "pd.DataFrame(np.random.rand(3, 2),columns=['foo', 'bar'],index=['a', 'b', 'c'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Indexing numpy array\n",
    "x4[:5] #Elements after index 5\n",
    "x4[::2] #Every other element\n",
    "x4[1::2] #starting from index 1,every other element\n",
    "x4[5::-2] # reversed every other from index 5\n",
    "#Similar for multiarrays\n",
    "x2[::-1,::-1]\n",
    "#Slicing in Series\n",
    "#First, the loc attribute allows indexing and slicing that always references the explicit index\n",
    "#The iloc attribute allows indexing and slicing that always references the implicit\n",
    "#Python-style index\n",
    "#The ix indexer allows a hybrid of these two approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One important—and extremely useful—thing to know about array slices is that \n",
    "#they return views rather than copies of the array data. If we modify the views, original data will change\n",
    "#if we want to copy:\n",
    "x2_sub_copy = x2[:2, :2].copy() \n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "#Reshape\n",
    "grid = np.arange(1, 10).reshape((3, 3)) \n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenation\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([3, 2, 1])\n",
    "grid = np.concatenate([x, y]) # concatenate on rows\n",
    "np.concatenate([grid, grid], axis=1) # concatenate on columns\n",
    "x = np.array([1, 2, 3])\n",
    "grid = np.array([[9, 8, 7],[6, 5, 4]]) # vertically stack the arrays\n",
    "np.vstack([x, grid])\n",
    "y = np.array([99],\n",
    "            [99])\n",
    "np.hstack([grid,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting\n",
    "x = [1, 2, 3, 99, 99, 3, 2, 1]\n",
    "x1, x2, x3 = np.split(x, [3, 5])\n",
    "print(x1, x2, x3)\n",
    "\n",
    "grid = np.arange(16).reshape((4, 4))\n",
    "upper, lower = np.vsplit(grid, [2])\n",
    "left, right = np.hsplit(grid, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aggregates and sorting\n",
    "x = np.arange(1, 6)\n",
    "np.add.reduce(x)\n",
    "np.multiply.reduce(x)\n",
    "np.add.accumulate(x)\n",
    "np.multiply.accumulate(x)\n",
    "x = np.array([2, 1, 4, 3, 5])\n",
    "np.sort(x)\n",
    "i = np.argsort(x) #returns the indices of the sorted array\n",
    "j = np.partition(x, 3) #returns the smallest 3 \n",
    "#Others\n",
    "#np.sum, np.prod,np.mean,np.std,np.var,np.min,np.max,np.argmin,np.median,np.percentile,np.any,np.all\n",
    "#note that if we add nan, it will be the NaN safe version: eg np.nansum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other useful functions\n",
    "indices = np.random.choice(X.shape[0], 20, replace=False) #random selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.values will give a numpy array for a pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Data Frame in pandas could be considered as a sequence of aligned Series objects. Aligned means that \n",
    "#they share the same index\n",
    "#Example 1\n",
    "population_dict = {'California': 38332521,\n",
    "                               'Texas': 26448193,\n",
    "                               'New York': 19651127,\n",
    "                               'Florida': 19552860,\n",
    "                               'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "states = pd.DataFrame({'population': population,\n",
    "                                   'area': area})\n",
    "states\n",
    "#Example 2\n",
    "test1 = pd.Series([1,2,3,4])\n",
    "test2 = pd.Series([5,6,7,8])\n",
    "test = pd.DataFrame({'feature1':test1,'feature2':test2})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert between Index and columns in pandas\n",
    "tick = pd.Series(['2013','2014','2015'])\n",
    "tag = pd.Series(['A','B','C'])\n",
    "obs = pd.Series([2,2,6])\n",
    "val = pd.Series([0.01,0.02,0.03])\n",
    "df = pd.DataFrame({'tick':tick,'tag':tag,'obs':obs,'val':val})\n",
    "df = df.set_index([df['tick'],df['tag'],df['obs']])\n",
    "df = df.drop('tick',1)\n",
    "df = df['val']\n",
    "df = df.reset_index(level=['tick','obs'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenation with joins\n",
    "pd.concat([df5, df6], join='inner') # only common columns, default is outjoin with NA filled in\n",
    "pd.concat([df5, df6], join_axes=[df5.columns])\n",
    "pd.concat([df5, df6], join_axes=[df5.columns])\n",
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge and join\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],'hire_date': [2004, 2008, 2012, 2014]})\n",
    "df3 = pd.merge(df1, df2)\n",
    "pd.merge(df1, df2, on='employee')\n",
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\").drop('name', axis=1)\n",
    "pd.merge(df6, df7, how='outer')\n",
    "pd.merge(df6, df7, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example\n",
    "#Read data\n",
    "pop = pd.read_csv('state-population.csv')\n",
    "areas = pd.read_csv('state-areas.csv')\n",
    "abbrevs = pd.read_csv('state-abbrevs.csv')\n",
    "print(pop.head()); print(areas.head()); print(abbrevs.head())\n",
    "#Merge data\n",
    "merged = pd.merge(pop, abbrevs, how='outer',left_on='state/region', right_on='abbreviation')\n",
    "merged = merged.drop('abbreviation', 1) # drop duplicate info \n",
    "merged.head()\n",
    "#Check missing\n",
    "merged.isnull().any()\n",
    "merged[merged['population'].isnull()].head()\n",
    "merged.loc[merged['state'].isnull(), 'state/region'].unique()\n",
    "#Fix missing\n",
    "merged.loc[merged['state/region'] == 'PR', 'state'] = 'Puerto Rico'\n",
    "merged.loc[merged['state/region'] == 'USA', 'state'] = 'United States'\n",
    "merged.isnull().any()\n",
    "#Repeat for another data source\n",
    "final = pd.merge(merged, areas, on='state', how='left')\n",
    "final.head()\n",
    "final.isnull().any()\n",
    "final['state'][final['area (sq. mi)'].isnull()].unique()\n",
    "final.dropna(inplace=True) #why inplace has to be set as True?\n",
    "final.head()\n",
    "# data slicing\n",
    "data2010 = final.query(\"year == 2010 & ages == 'total'\")\n",
    "data2010.head()\n",
    "# Compute population density\n",
    "data2010.set_index('state', inplace=True)\n",
    "density = data2010['population'] / data2010['area (sq. mi)']\n",
    "#Sort\n",
    "density.sort_values(ascending=False, inplace=True)\n",
    "density.head()\n",
    "density.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aggregation,Grouping and Filtering\n",
    "#Aggregation\n",
    "planets.dropna().describe()\n",
    "df.groupby('key').aggregate({'data1': 'min','data2': 'max'})\n",
    "#Filtering\n",
    "def filter_func(x):\n",
    "    return x['data2'].std() > 4\n",
    "df.groupby('key').filter(filter_func)\n",
    "#Transformation\n",
    "df.groupby('key').transform(lambda x: x - x.mean())\n",
    "#Apply - ?\n",
    "def norm_by_data2(x):\n",
    "# x is a DataFrame of group values\n",
    "    x['data1'] /= x['data2'].sum() return x\n",
    "print(df); print(df.groupby('key').apply(norm_by_data2))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#String operations\n",
    "#Nearly all Python’s built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas str methods that mirror Python string methods:\n",
    "#len() lower() ljust() upper() rjust() find() center() \n",
    "#rfind() zfill() index() strip() rindex() rstrip() capitalize() lstrip() swapcase()\n",
    "#translate() startswith() endswith() isalnum() isalpha() isdigit() isspace()\n",
    "#istitle() islower() isupper() isnumeric() isdecimal() split() rsplit() partition() rpartition()\n",
    "monte.str.extract('([A-Za-z]+)')\n",
    "monte.str.findall(r'^[^AEIOU].*[^aeiou]$')\n",
    "recipes.description.str.contains('[Bb]reakfast').sum()\n",
    "#More string manipulations in python or pandas? \n",
    "selection = spice_df.query('parsley & paprika & tarragon')\n",
    "recipes.name[selection.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Time series\n",
    "dates = pd.to_datetime([datetime(2015, 7, 3), '4th of July, 2015',\n",
    "                                   '2015-Jul-6', '07-07-2015', '20150708']) #could specific format same as in R\n",
    "dates.to_period('D')\n",
    "pd.date_range('2015-07-03', periods=8, freq='H')\n",
    "pd.period_range('2015-07', periods=8, freq='M')\n",
    "pd.timedelta_range(0, periods=10, freq='H')\n",
    "pd.timedelta_range(0, periods=9, freq=\"2H30T\")\n",
    "\n",
    "goog.plot(alpha=0.5, style='-')\n",
    "goog.resample('BA').mean().plot(style=':')\n",
    "goog.asfreq('BA').plot(style='--');\n",
    "plt.legend(['input', 'resample', 'asfreq'],loc='upper left');\n",
    "\n",
    "fig, ax = plt.subplots(2, sharex=True)\n",
    "data = goog.iloc[:10]\n",
    "data.asfreq('D').plot(ax=ax[0], marker='o')\n",
    "data.asfreq('D', method='bfill').plot(ax=ax[1], style='-o')\n",
    "data.asfreq('D', method='ffill').plot(ax=ax[1], style='--o')\n",
    "ax[1].legend([\"back-fill\", \"forward-fill\"]);\n",
    "\n",
    "#Use time shift to compute returns\n",
    "ROI = 100 * (goog.tshift(-365) / goog - 1)\n",
    "ROI.plot()\n",
    "plt.ylabel('% Return on Investment');\n",
    "\n",
    "#Rolling window\n",
    "rolling = goog.rolling(365, center=True)\n",
    "data = pd.DataFrame({'input': goog,'one-year rolling_mean': rolling.mean(),'one-year rolling_std': rolling.std()})\n",
    "ax = data.plot(style=['-', '--', ':'])\n",
    "ax.lines[0].set_alpha(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example\n",
    "# !curl -o FremontBridge.csv\n",
    "# https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD\n",
    "data = pd.read_csv('FremontBridge.csv', index_col='Date', parse_dates=True)\n",
    "data.head()\n",
    "data.columns = ['West', 'East']\n",
    "data['Total'] = data.eval('West + East')\n",
    "data.dropna().describe()\n",
    "#\n",
    "weekly = data.resample('W').sum()\n",
    "weekly.plot(style=[':', '--', '-'])\n",
    "plt.ylabel('Weekly bicycle count');\n",
    "#\n",
    "daily = data.resample('D').sum()\n",
    "daily.rolling(30, center=True).sum().plot(style=[':', '--', '-'])\n",
    "plt.ylabel('mean hourly count');\n",
    "daily.rolling(50, center=True,win_type='gaussian').sum(std=10).plot(style=[':', '--', '-']);\n",
    "#\n",
    "by_time = data.groupby(data.index.time).mean()\n",
    "hourly_ticks = 4 * 60 * 60 * np.arange(6)\n",
    "by_time.plot(xticks=hourly_ticks, style=[':', '--', '-']);\n",
    "#\n",
    "by_weekday = data.groupby(data.index.dayofweek).mean()\n",
    "by_weekday.index = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\n",
    "by_weekday.plot(style=[':', '--', '-']);\n",
    "#\n",
    "weekend = np.where(data.index.weekday < 5, 'Weekday', 'Weekend')\n",
    "by_time = data.groupby([weekend, data.index.time]).mean()\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5)) by_time.ix['Weekday'].plot(ax=ax[0], title='Weekdays',xticks=hourly_ticks, style=[':', '--', '-'])\n",
    "by_time.ix['Weekend'].plot(ax=ax[1], title='Weekends',xticks=hourly_ticks, style=[':', '--', '-']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#High-Performance Pandas: eval() and query() - Need more readings\n",
    "result1 = -df1 * df2 / (df3 + df4) - df5\n",
    "result2 = pd.eval('-df1 * df2 / (df3 + df4) - df5')\n",
    "#\n",
    "result1 = (df1 < 0.5) & (df2 < 0.5) | (df3 < df4)\n",
    "result2 = pd.eval('(df1 < 0.5) & (df2 < 0.5) | (df3 < df4)')\n",
    "#\n",
    "df.eval('D = (A + B) / C', inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
