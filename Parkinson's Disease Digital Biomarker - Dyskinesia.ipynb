{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy as scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.fftpack\n",
    "from scipy import signal\n",
    "from time import gmtime, strftime\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Method responsible for creating and applying Butterworth filter.\n",
    "\n",
    "        :param deque data: raw data\n",
    "\n",
    "        :param float lowcut: filter lowcut frequency value\n",
    "\n",
    "        :param float highcut: filter highcut frequency value\n",
    "\n",
    "        :param int signal_freq: signal frequency in samples per second (Hz)\n",
    "\n",
    "        :param int filter_order: filter order\n",
    "\n",
    "        :return array: filtered data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        nyquist_freq = 0.5 * signal_freq\n",
    "\n",
    "        low = lowcut / nyquist_freq\n",
    "\n",
    "        high = highcut / nyquist_freq\n",
    "\n",
    "        b, a = butter(filter_order, [low, high], btype=\"band\")\n",
    "\n",
    "        y = lfilter(b, a, data)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_info = pd.read_csv('D:/Parkinson Data L-Dopa Test/data_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tremor_data = data_info[data_info['dyskinesiaScore']=='Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat2 = tremor_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:10<00:00, 64.24it/s]\n"
     ]
    }
   ],
   "source": [
    "distance = []\n",
    "dis_variance = []\n",
    "dis_median = []\n",
    "dis_80 = []\n",
    "dis_95 = []\n",
    "for i in tqdm.tqdm(range(len(dat2))):\n",
    "    x = pd.read_csv(dat2['Path'][i],sep='\\t').astype(float)\n",
    "    x.columns = ['timestamp','X','Y','Z','W']\n",
    "    x['timestamp'] = (x['timestamp']-x['timestamp'][0])\n",
    "    if(x['X'].isnull().sum()>0):\n",
    "        distance.append(np.nan)\n",
    "        dis_variance.append(np.nan)\n",
    "        dis_median.append(np.nan)\n",
    "        dis_80.append(np.nan)\n",
    "        dis_95.append(np.nan)\n",
    "    else:\n",
    "        x1 = bandpass_filter(x['X'], lowcut=3,highcut=8, signal_freq=50,filter_order=2)\n",
    "        y1 = bandpass_filter(x['Y'], lowcut=3,highcut=8, signal_freq=50,filter_order=2)\n",
    "        z1 = bandpass_filter(x['Z'], lowcut=3,highcut=8, signal_freq=50,filter_order=2)\n",
    "        v = np.sqrt((x1.cumsum()*0.02)*(x1.cumsum()*0.02)+(y1.cumsum()*0.02)*(y1.cumsum()*0.02)+(z1.cumsum()*0.02)*(z1.cumsum()*0.02))\n",
    "        s = v*0.02\n",
    "        total_distance = np.sum(s)    \n",
    "        distance.append(total_distance/(len(x)/50))\n",
    "        dis_variance.append(np.var(v))\n",
    "        dis_median.append(np.median(v))\n",
    "        dis_80.append(np.percentile(v,80))\n",
    "        dis_95.append(np.percentile(v,95))\n",
    "\n",
    "dat2['distance'] = distance\n",
    "dat2['dis_var'] = dis_variance\n",
    "dat2['dis_median'] = dis_median\n",
    "dat2['dis_80'] = dis_80\n",
    "dat2['dis_95'] = dis_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:16<00:00, 39.24it/s]\n"
     ]
    }
   ],
   "source": [
    "pca_abs_mean = []\n",
    "pca_mean = []\n",
    "pca_var = []\n",
    "pca_abs_max = []\n",
    "exp_var = []\n",
    "c_mean = []\n",
    "c_median = []\n",
    "c_std = []\n",
    "#dat2 = tremor_data[(tremor_data['task'].str.contains('ftn')&(tremor_data['site']=='Boston'))].reset_index()\n",
    "for i in tqdm.tqdm(range(len(dat2))):\n",
    "    x = pd.read_csv(dat2['Path'][i],sep='\\t').astype(float)\n",
    "    x.columns = ['timestamp','X','Y','Z','W']\n",
    "    x['timestamp'] = (x['timestamp']-x['timestamp'][0])\n",
    "    if(x['X'].isnull().sum()>0):\n",
    "        pca_abs_mean.append(np.nan)\n",
    "        pca_mean.append(np.nan)\n",
    "        pca_var.append(np.nan)\n",
    "        pca_abs_max.append(np.nan)\n",
    "        exp_var.append(np.nan)\n",
    "        c_mean.append(disc_mean)\n",
    "        c_median.append(disc_median)\n",
    "        c_std.append(disc_std)\n",
    "    else:\n",
    "        x1 = bandpass_filter(x['X'], lowcut=3,highcut=8, signal_freq=50,filter_order=2)\n",
    "        y1 = bandpass_filter(x['Y'], lowcut=3,highcut=8, signal_freq=50,filter_order=2)\n",
    "        z1 = bandpass_filter(x['Z'], lowcut=3,highcut=8, signal_freq=50,filter_order=2)\n",
    "        px = x1.cumsum().cumsum()*0.02*0.02\n",
    "        py = y1.cumsum().cumsum()*0.02*0.02\n",
    "        pz = z1.cumsum().cumsum()*0.02*0.02\n",
    "        p = pd.DataFrame([px,py,pz]).transpose()\n",
    "        pca = PCA().fit(p)\n",
    "        exp_var.append(pca.explained_variance_ratio_[2])\n",
    "        pca = PCA(n_components=3)\n",
    "        pca.fit(p)\n",
    "        x_pca = pca.transform(p)\n",
    "        pca_abs_mean.append(np.mean(np.abs(x_pca[:,2])))\n",
    "        pca_mean.append(np.mean(x_pca[:,2]))\n",
    "        pca_var.append(np.var(x_pca[:,2]))\n",
    "        pca_abs_max.append(np.max(np.abs(x_pca[:,2])))\n",
    "        \n",
    "        xc = np.median(px)\n",
    "        yc = np.median(py)\n",
    "        zc = np.median(pz)\n",
    "        dis_c = np.sqrt((x1-xc)*(x1-xc)+(y1-yc)*(y1-yc)+(z1-zc)*(z1-zc))\n",
    "        disc_mean = np.mean(dis_c)\n",
    "        disc_median = np.median(dis_c)\n",
    "        disc_std = np.std(dis_c)\n",
    "        \n",
    "        c_mean.append(disc_mean)\n",
    "        c_median.append(disc_median)\n",
    "        c_std.append(disc_std)\n",
    "dat2['pca_abs_mean'] = pca_abs_mean\n",
    "dat2['pca_mean'] = pca_mean\n",
    "dat2['pca_var'] = pca_var\n",
    "dat2['pca_abs_max'] = pca_abs_max\n",
    "dat2['exp_var'] = exp_var\n",
    "dat2['c_mean'] = c_mean\n",
    "dat2['c_median'] = c_median\n",
    "dat2['c_std'] = c_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:07<00:00, 90.77it/s] \n"
     ]
    }
   ],
   "source": [
    "powerx = []\n",
    "powery = []\n",
    "powerz = []\n",
    "f_s = 50\n",
    "for i in tqdm.tqdm(range(len(dat2))):\n",
    "    x = pd.read_csv(dat2['Path'][i],sep='\\t').astype(float)\n",
    "    x.columns= ['time','X','Y','Z','W']\n",
    "    data1 = x['X']\n",
    "    data2 = x['Y']\n",
    "    data3 = x['Z']\n",
    "    freqs = scipy.fftpack.fftfreq(len(x['X'])) * f_s\n",
    "    if(x['X'].isnull().sum()>0):\n",
    "        powerx.append(np.nan)\n",
    "        powery.append(np.nan)\n",
    "        powerz.append(np.nan)\n",
    "    else:    \n",
    "        p = pd.DataFrame([data1,data2,data3]).transpose()\n",
    "        pca = PCA(n_components=3)\n",
    "        pca.fit(p)\n",
    "        x_pca = pca.transform(p)\n",
    "        x1 = np.abs(scipy.fftpack.fft(x_pca[:,0]))[(freqs>=1)&(freqs<=8)].sum()\n",
    "        y1 = np.abs(scipy.fftpack.fft(x_pca[:,1]))[(freqs>=1)&(freqs<=8)].sum()\n",
    "        z1 = np.abs(scipy.fftpack.fft(x_pca[:,2]))[(freqs>=1)&(freqs<=8)].sum()\n",
    "        powerx.append(x1)\n",
    "        powery.append(y1)\n",
    "        powerz.append(z1)\n",
    "dat2['powerx'] = powerx\n",
    "dat2['powery'] = powery\n",
    "dat2['powerz'] = powerz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 333/660 [00:08<00:07, 40.90it/s]C:\\Users\\wangs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in arccos\n",
      "C:\\Users\\wangs\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3858: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "100%|██████████| 660/660 [00:14<00:00, 44.08it/s]\n"
     ]
    }
   ],
   "source": [
    "angle_median = []\n",
    "angle_mean = []\n",
    "angle_std = []\n",
    "for i in tqdm.tqdm(range(len(dat2))):\n",
    "    x = pd.read_csv(dat2['Path'][i],sep='\\t').astype(float)\n",
    "    x.columns= ['time','X','Y','Z','W']\n",
    "    if(x['X'].isnull().sum()>0):\n",
    "        angle_median.append(np.nan)\n",
    "        angle_mean.append(np.nan)\n",
    "        angle_std.append(np.nan)\n",
    "    else:    \n",
    "        x1 = bandpass_filter(x['X'], lowcut=2,highcut=20, signal_freq=50,filter_order=2)\n",
    "        y1 = bandpass_filter(x['Y'], lowcut=2,highcut=20, signal_freq=50,filter_order=2)\n",
    "        z1 = bandpass_filter(x['Z'], lowcut=2,highcut=20, signal_freq=50,filter_order=2)\n",
    "        new = pd.DataFrame([x1,y1,z1]).transpose()\n",
    "        new2 = new[0:-1].values\n",
    "        new3 = new[1:].values\n",
    "        new2sum = np.sqrt(new2[:,0]*new2[:,0]+new2[:,1]*new2[:,1]+new2[:,2]*new2[:,2])\n",
    "        new3sum = np.sqrt(new3[:,0]*new3[:,0]+new3[:,1]*new3[:,1]+new3[:,2]*new3[:,2])\n",
    "        newsum = new2*new3\n",
    "        cos = pd.DataFrame(newsum).sum(axis=1)/(new2sum*new3sum)\n",
    "        arccos = np.arccos(cos)/3.1415926*180\n",
    "        angle_median.append(np.median(arccos))\n",
    "        angle_mean.append(np.mean(arccos))\n",
    "        angle_std.append(np.std(arccos))\n",
    "\n",
    "dat2['angle_median'] = angle_median\n",
    "dat2['angle_mean'] = angle_mean\n",
    "dat2['angle_std'] = angle_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SampEn(U, m, r):\n",
    "    std = np.std(U)\n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "    def _phi(m):\n",
    "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [(len([1 for x_j in x if _maxdist(x_i, x_j) <= r*std])) - 1 for x_i in x]\n",
    "        return sum(C)+0.0000001\n",
    "\n",
    "    N = len(U)\n",
    "\n",
    "    return np.log(_phi(m)/_phi(m+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(U,n,m,r): ## return the SampEn for U up to scale n\n",
    "    mse = []\n",
    "    for i in range(n):\n",
    "        d = U[0:-1:(i+1)].values\n",
    "        mse.append(SampEn(d,m,r))\n",
    "    return np.array(mse)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/660 [00:00<?, ?it/s]\n",
      "100%|██████████| 660/660 [1:32:08<00:00,  8.95s/it]\n"
     ]
    }
   ],
   "source": [
    "mse_scorex = []\n",
    "mse_scorey = []\n",
    "mse_scorez = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(dat2))):\n",
    "    p = dat2['Path'].values[i]\n",
    "    test = pd.read_csv(p,sep='\\t').astype(float)\n",
    "    test.columns = ['time','X','Y','Z','M']\n",
    "    test['time'] = test['time']-test['time'].values[0]\n",
    "    mse_scorex.append(MSE(test['X'],10,2,0.2))\n",
    "    mse_scorey.append(MSE(test['Y'],10,2,0.2))\n",
    "    mse_scorez.append(MSE(test['Z'],10,2,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = pd.concat([pd.DataFrame(mse_scorex),pd.DataFrame(mse_scorey),pd.DataFrame(mse_scorez)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.columns = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10',\n",
    "                'y1','y2','y3','y4','y5','y6','y7','y8','y9','y10',\n",
    "                'z1','z2','z3','z4','z5','z6','z7','z8','z9','z10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([dat2,score],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat3 = data.copy().drop(['tremorScore','bradykinesiaScore','index','idx','Path'],axis=1)\n",
    "dat3.to_csv('D:/Parkinson Data L-Dopa Test/dyskinesia_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
